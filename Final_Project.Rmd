---
title: "Final Project"
author: "Bridget Silha"
date: "12/14/2019"
header-includes:
   - \usepackage{setspace}
   - \doublespacing
output:
  pdf_document:
    latex_engine: xelatex
fontsize: 12pt
---

```{r, include = FALSE}
require(tidyverse)
require(caret) # for machine learning
require(recipes) # For preprocessing your data
require(rattle) # For nice tree plots
require(lubridate) # For rounding dates

doMC::registerDoMC()
```

# Introduction

The aim of this project is to analyze and predict the factors necessary for producing an Independent Expenditure-Only Committee (Super PAC). There are several goals of this project including:

- Analyze which states are more likely to register Super PACs
- Assess the scale and magnitude of the effect that Citizens United v. FEC had on FEC filings and registration
- Discuss the financial statements of Super PACs compared to other political committees during the 2018 Election Cycle
- Using supervised learning, judge whether or not classification algorithms can be respectfully used in order to predict whether a political committee is a Super PAC or not

For this project, I will be using data from the Federal Election Commission (FEC) website from the 2018 Election Cycle. First, I will join together political action committee (PAC) information with their financial statements from that election cycle. After cleaning that dataset, I will then analyze several variables in-depth (including registered state, disbursments, contributions, receipts, and filing time). Finally, I will create several models that attempt to predict with respectable accuracy if a political committee is a Super PAC or not. 

# Problem Statement and Background

- Give a clear and complete statement of the problem and/or aim of your analysis.
- Include a brief summary of any related work that has tried to tackle a project similar to
yours (i.e. a light literature review)

The Federal Election Commisssion (FEC) is an independent, governmental agency that is responsible for "administering and enforcing campaign finance law".[^1] They are also responsible for financial disclosure statements to/from candidates and committees that influence public office. These records are public information. Many committees, such as PACs and individuals, are subject to contribution limits. However, Independent Expenditure-Only Committees (Super PACs) are not. 

Super PACs were initiated in January 2010 after *Citizens United v. FEC* was decided. The Supreme Court in this case maintained that freedom of speech was essential to democracy and that speech from a corporation was no exception. This new kind of committee would be able to bypass fundraising and expenditure limitations set on other political committees. The only limitation Super PACs have is that they may not coordinate with candidates in their express advocacy for/against them. Since their birth early this decade, Super PACs have collectively spent over $2 billion.[^2] 

[^1]: https://www.fec.gov/about/mission-and-history/
[^2]: https://fas.org/sgp/crs/misc/R42042.pdf 

# Data

The two datasets that I patched together were taken from the FEC's regularly maintained website. The unit of observation is *committee id*. 
Below are the steps that I did in order to wrangle the data: 

1. Read in CSVs from FEC website

```{r, include=FALSE}
## -------------------------------------- Data: Reading in Data --------------------------------------------##

#Read CVS data in
total_fec_committee_party_and_pac <- read_csv("committees.csv")
##DATA DESCRIPTION FOR COMMITTEE TYPE: https://www.fec.gov/campaign-finance-data/committee-type-code-descriptions/ 

pac_financial_info_2018 <- read_csv("committee_summary_2018.csv")
##DATA DESCRIPTION: https://www.fec.gov/campaign-finance-data/committee-summary-file-description/ 
```

2. Joined the two CSVs based on *committee id*

```{r, include = FALSE}
## ----------------------------------- Data: Combining CVS ---------------------------------##

#Bind 2018 committee information and financial information together
new_data <- right_join(total_fec_committee_party_and_pac, pac_financial_info_2018, by=c("committee_id" = "CMTE_ID"), c("name" = "CMTE_NM"))

```

3. Cut down unnecessary variables in the dataset (such as committee treasurer name and committee zipcode)

```{r}
## ----------------------------------- Data: Cut Down Unnecesary Variables ---------------------------------##

#Cut down variables
new_data <- new_data %>% 
  select (-Link_Image, -CMTE_ST1:-CMTE_CITY, -CMTE_ZIP:-CAND_ID, -INDV_CONTB:-OTH_CMTE_CONTB, -TRANF_FROM_OTHER_AUTH_CMTE:-OTHER_RECEIPTS, -TRANF_TO_OTHER_AUTH_CMTE:-OTHER_DISB, -NET_CONTB:-TTL_COMMUNICATION_COST, -COH_BOY, -COH_COY, -name, -cycles, -treasurer_name, -filing_frequency:-affiliated_committee_name, -party_full, -candidate_ids, -FEC_ELECTION_YR, -CMTE_TP)

#Committee name and commmitte id as first variables
new_data <- new_data %>% 
  select (CMTE_NM, committee_id, everything())
```

4. Filtered out results to only accept PAC committees based on the variable *committee_type*

```{r}
## ------------- Data: Filter for PACs ------------------------------##

#Filter for committee type -- only PACs
new_data <- new_data %>% 
  filter(committee_type == "N" | committee_type == "O" | committee_type == 
           "Q" | committee_type == "V" | committee_type == "W")
```

5. Filtered out committees that had been terminated in the past based on the variable *CMTE_FILING_FREQ*

```{r}
## --------------- Data: Filter for Active Committees ----------------##

#Filter out terminated committees
new_data <- new_data %>% 
  filter(CMTE_FILING_FREQ == "M" | CMTE_FILING_FREQ == "Q")
```


6. Made *first_filing_date*, *last_f1_date*, and *last_file_date* variables into a "Date" class


```{r, include = FALSE}
## ----------------------------------- Data: Changing variables to Date using lubridate ---------------------------------##

# Formatting original columns as MM-DD-YY format
new_data$first_file_date <- as.Date(new_data$first_file_date, format = "%m/%d/%y")
new_data$last_f1_date <- as.Date(new_data$last_f1_date, format = "%m/%d/%y")
new_data$last_file_date <- as.Date(new_data$last_file_date, format = "%m/%d/%y")

# Round to nearest month
new_data$first_file_month <- round_date(new_data$first_file_date, unit = "month"); new_data$first_file_month
new_data$last_f1_date_month <- round_date(new_data$last_f1_date, "month")
new_data$last_file_date_month <- round_date(new_data$last_file_date, "month")

# Name the variables the month name
new_data$first_file_month <- as.Date(new_data$first_file_month, format = "%B"); new_data$first_file_month
new_data$last_f1_date_month <- as.Date(new_data$last_f1_date_month, format = "%B")
new_data$last_file_date_month <- as.Date(new_data$last_file_date_month, format = "%B")

# Round to nearest year
new_data$first_file_year <- round_date(new_data$first_file_date, unit = "year")
new_data$last_f1_date_year <- round_date(new_data$last_f1_date, "year")
new_data$last_file_date_year <- round_date(new_data$last_file_date, "year")

# Name the variables the year name
new_data$first_file_year <- as.Date(new_data$first_file_year, format = "%Y")
new_data$last_f1_date_year <- as.Date(new_data$last_f1_date_year, format = "%Y")
new_data$last_file_date_year <- as.Date(new_data$last_file_date_year, format = "%Y")


str(new_data)
```


7. Created a new variable for the dataset, *SuperPAC_yes*, which identifies whether or not the specific observation is a SuperPAC based on *committee_type*


```{r, include = FALSE}
## ----------------------------------- Cleaning data: Adding new Super PAC_yes response variable ---------------------------------##


# Add new variable to dataset
# if , Then _yes = 1

new_data <- new_data %>% 
  mutate(SuperPAC_yes = recode(committee_type, "O" = 1, "N" = 0, "V" = 0, "W" = 0, "Q" = 0, .default = 0))

skimr::skim(new_data)

```

Below you can see the variables of interest:
```{r}
new_data %>% glimpse()
```

# Analysis 

– Describe the methods/tools you explored in your project.
– Outline in detail your entire analysis.
  - Justify the tools/methods that you used.
  - Assume the reader is smart but doesn’t know R/Machine Learning well. That is, be
crystal clear about what you’re doing and why.

## Split the Data

First, I split the *new_data* dataset into two further datasets based on our response variables, *SuperPAC_yes*. These datasets, the training and test dataset, are essential to verify that any model or predictions that are made can be applied to "unseen" data. By doing this, we can also reduce the error for "overfitting" the model to our training data. For this analysis, the training and test data will share an 80-20 split of the response variable values. 

```{r, include = FALSE}
## --------------------- Splitting data into training and test datasets -------------------##

#split into training and test data
index = createDataPartition(new_data$SuperPAC_yes,p=.8,list=F) 
train_data = new_data[index,] # Use 80% of the data as training data 
test_data = new_data[-index,] # holdout 20% as test data 

# Proporation in the training data 
round(nrow(train_data)/nrow(new_data),3)

# Proporation in the test data 
round(nrow(test_data)/nrow(new_data),3)

#number of observations in training data
dim(train_data)
dim(test_data)



```

## Understanding the Outcome

Our response variable, *SuperPAC_yes*, has been manually created based off of another variables, *committee_type*. It takes on the value of "1" if the committee is a Super PAC and "0" if it is any other type of PAC. In the training dataset, there seems to be roughly a 1:4 ratio between Super PAC and other PAC types. There are 4,967 observations in the training dataset. 

```{r}

train_data %>% 
  ggplot(aes(SuperPAC_yes)) +
  geom_bar()

train_data %>% nrow()

```

## Understanding the Features

### Conlusions

Looking at the categorical variables in the dataset, there seems to be good variation in variables such as *ORG_TP* and *CMTE_FILING_FREQ*. In the variable *committee_type*, there seems to be over-represetnation from PAC types like "PAC - Qualified" and "PAC - Nonqualified" (shown as "Q" and "N" below) compared to PAC with Non-contribution Account - Nonqualified" and "PAC with Non-contribution Account - Nonqualified" (shown as "W" and "V" below). 

```{r, echo = FALSE}
## --------------------- Data Visualization: categorical variables -------------------##

#Summary
skimr::skim(train_data)

#Visualize distribution of categorical variables
train_data %>% 
  select(CMTE_DSGN, CMTE_FILING_FREQ, committee_type, ORG_TP) %>% 
  gather(var,val) %>% 
  ggplot(aes(val)) +
  geom_bar() +
  scale_y_log10() +
  facet_wrap(~var,scales="free",ncol=3)
```

- There's a peak around late 2019 for last_f1_date
- last_file_date is consistant with committee filing frequency
- There's a peak around 2008 for times when committees first filed with the FEC

When looking at the date variables within the training dataset, there are several trends that can be observed. For example, when plotting *last_file_date* frequencies, we can see that the most frequent filing date months for the 2018 election year was in July and October. This is consistent with the information that we found from *CMTE_FILING_FREQ* in which most committees file on a quarterly basis (Q3 being in October) while only some file on a semi-annual basis (semi-annual deadline being in July). 


```{r, echo = FALSE}
## ------------------------- Data Visualization: date variables ---------------------##

#Visualize distribution of date variables

train_data %>% 
ggplot(aes(x=last_file_date)) + 
  geom_histogram(binwidth=5, colour="white") +
       ylab("Frequency") + 
  xlab("Year and Month") +
       theme_bw()

train_data %>% 
ggplot(aes(x=first_file_date)) + 
  geom_histogram(binwidth=100, colour="white") +
       ylab("Frequency") + 
  xlab("Year") +
       theme_bw()

train_data %>% 
ggplot(aes(x=last_f1_date)) + 
  geom_histogram(binwidth=50, colour="white") +
       ylab("Frequency") + 
  xlab("Year") +
       theme_bw()


```


## Understanding the Relationship Between Features

### Conclusions:
- Many of the usual suspects of swing states and power states (i.e. VA, DC, NY, CA) have the most PACs but most of them are made up of PAC-qualified, not Super PACs
- States do not differ a lot when it comes to total disbursements/total contributions that PACs raise/spend
- It is obvious that PAC-Qualified is the committee type that most often spends and receives the most in each state
- Since Citizens United case, the "first filing date" of Super PACs and PAC - Nonqualified committees have increased exponentially
- The Citizens United case seems to indicate the start of the majority of "first filing" dates for Super PACs

```{r, echo = FALSE}
## ------------------------- Data Visualization: More in-depth ---------------------##

# Load
require ("RColorBrewer")

#Coverage over states vs. initial filing date grouped by committee type
new_data %>% 
  ggplot(aes(first_file_date, CMTE_ST, color = factor(committee_type))) +
  geom_point(show.legend = T) +
  geom_vline(xintercept = as.numeric(as.Date("2010-01-21"))) +
  #Line to show when Citizens United became official
  scale_fill_discrete(name="PAC Type",
                         breaks=c("O", "N", "Q", "V", "W"),
                         labels = c("Independent Expenditure-Only (Super PACs)", "PAC - Nonqualified", "PAC - Qualified", "PAC with Non-contribution Account - Nonqualified", "PAC with Non-contribution Account - Qualified")) +
  scale_colour_manual(name="PAC Type",
                      breaks=c("N", "O", "Q", "V", "W"), 
                      values = c((brewer.pal(5,"Set1"))),
                      labels = c("Independent Expenditure-Only (Super PACs)", "PAC - Nonqualified", "PAC - Qualified", "PAC with Non-contribution Account - Nonqualified", "PAC with Non-contribution Account - Qualified")) +
  ggtitle("PAC Filing Over Time by State and PAC Type") +
  xlab ("First File Date") +
  ylab ("State of Registration")

```


```{r, echo = FALSE}
## -------------------------------- Data Visualization: Round Dates ----------------------------##

#Visualize 
train_data1 %>% 
  select(first_file_date) %>% 
  gather(var,val) %>% 
  ggplot(aes(val)) +
  stat_count(width = 10) +
  scale_y_log10() +
  facet_wrap(~var,scales="free",ncol=3) +
  coord_flip()

#PAC Filing over Time by PAC Type
train_data1 %>% 
  ggplot(aes(first_file_date, color = committee_type)) +
  geom_bar() +
  stat_count(width = 10) +
  scale_fill_discrete(name="PAC Type",
                         breaks=c("N", "O", "Q", "V", "W"),
                         labels = c("PAC - Nonqualified", "Independent expenditure-only (Super PACs)", "PAC - Qualified", "PAC with non-contribution account - Nonqualified", "PAC with non-contribution account - Qualified")) +
  scale_colour_manual(name="PAC Type",
                      breaks=c("N", "O", "Q", "V", "W"), 
                      values = c((brewer.pal(5,"Set1"))),
                      labels = c("PAC - Nonqualified", "Independent expenditure-only (Super PACs)" , "PAC - Qualified", "PAC with non-contribution account - Nonqualified", "PAC with non-contribution account - Qualified")) +
  xlab("Date of First Filing with FEC") +
  ylab("Number of PACs") +
  ggtitle("PAC Filing Over Time by PAC Type") +
  geom_vline(xintercept = as.numeric(as.Date("2010-01-21"))) +
  ggthemes::theme_tufte()



```

## Unpacking the Outcome

###Pre-process the data

```{r, include = FALSE}
## -------------------------------- Pre-Process the Data: Log money variables ----------------------------##
#Convert TTL_CONTB, TTL_RECEIPTS, TTL_DISB to log

convert_TTL_CONTB <- . %>% mutate(TTL_CONTB = log(TTL_CONTB+1))
convert_TTL_RECEIPTS <- . %>% mutate(TTL_RECEIPTS = log(TTL_RECEIPTS+1))
convert_TTL_DISB <- . %>% mutate(TTL_DISB = log(TTL_DISB+1))

#apply function to both training and test databases

train_data2 <- train_data1 %>%
  convert_TTL_CONTB() %>% 
  convert_TTL_RECEIPTS() %>% 
  convert_TTL_DISB()

test_data2 <- test_data1 %>% 
  convert_TTL_CONTB() %>% 
  convert_TTL_RECEIPTS() %>% 
  convert_TTL_DISB()

#Visualize
train_data2 %>% 
  ggplot(aes(TTL_CONTB)) +
  geom_histogram(binwidth = 1)

train_data2 %>% 
  ggplot(aes(TTL_DISB)) +
  geom_histogram(binwidth = 1)

train_data2 %>% 
  ggplot(aes(TTL_RECEIPTS)) +
  geom_histogram(binwidth = 1)


```

```{r, echo = FALSE}
## -------------------------------- Pre-Process the Data: Visualize log(money) variables ----------------------------##
#Mapped STATE vs. contributions
contb <- train_data2 %>% 
  ggplot(aes(TTL_CONTB, CMTE_ST, color = factor(committee_type))) +
    scale_fill_discrete(name="PAC Type",
                         breaks=c("O", "N", "Q", "V", "W"),
                         labels = c("Independent expenditure-only (Super PACs)", "PAC - Nonqualified", "PAC - Qualified", "PAC with non-contribution account - Nonqualified", "PAC with non-contribution account - Qualified")) +
  scale_colour_manual(name="PAC Type",
                      breaks=c("N", "O", "Q", "V", "W"), 
                      values = c((brewer.pal(5,"Set1"))),
                      labels = c("Independent expenditure-only (Super PACs)", "PAC - Nonqualified", "PAC - Qualified", "PAC with non-contribution account - Nonqualified", "PAC with non-contribution account - Qualified")) +
  geom_jitter(show.legend = T) +
  ggthemes::theme_tufte()

contb


#Mapped STATE vs. expenditures
disb <- train_data2 %>% 
  ggplot(aes(TTL_DISB, CMTE_ST, color = factor(committee_type))) +
    scale_fill_discrete(name="PAC Type",
                         breaks=c("O", "N", "Q", "V", "W"),
                         labels = c("Independent expenditure-only (Super PACs)", "PAC - Nonqualified", "PAC - Qualified", "PAC with non-contribution account - Nonqualified", "PAC with non-contribution account - Qualified")) +
  scale_colour_manual(name="PAC Type",
                      breaks=c("N", "O", "Q", "V", "W"), 
                      values = c((brewer.pal(5,"Set1"))),
                      labels = c("Independent expenditure-only (Super PACs)", "PAC - Nonqualified", "PAC - Qualified", "PAC with non-contribution account - Nonqualified", "PAC with non-contribution account - Qualified")) +
  geom_jitter(show.legend = T) +
  ggthemes::theme_tufte()

disb


#Mapped STATE vs. expenditures
receipt <- train_data2 %>% 
  ggplot(aes(TTL_RECEIPTS, CMTE_ST, color = factor(committee_type))) +
    scale_fill_discrete(name="PAC Type",
                         breaks=c("O", "N", "Q", "V", "W"),
                         labels = c("Independent expenditure-only (Super PACs)", "PAC - Nonqualified", "PAC - Qualified", "PAC with non-contribution account - Nonqualified", "PAC with non-contribution account - Qualified")) +
  scale_colour_manual(name="PAC Type",
                      breaks=c("N", "O", "Q", "V", "W"), 
                      values = c((brewer.pal(5,"Set1"))),
                      labels = c("Independent expenditure-only (Super PACs)", "PAC - Nonqualified", "PAC - Qualified", "PAC with non-contribution account - Nonqualified", "PAC with non-contribution account - Qualified")) +
  geom_jitter(show.legend = T) +
  ggthemes::theme_tufte()

receipt

```


```{r, include = FALSE}
###### ----------------------------- Recoding and recipe ---------------------------------######

#Turn party into an actual factor
train_data2 <- train_data2 %>% 
  mutate(party = ifelse(party == "DEM" | party == "REP" , party, "NONE"),
         party = ifelse(is.na(party), "NONE", party))

#Turn ORG_TP into an actual factor
train_data2 <- train_data2 %>% 
    mutate(ORG_TP = ifelse(ORG_TP == "C" | ORG_TP == "T" | ORG_TP == "M", ORG_TP, "NONE"),
         ORG_TP = ifelse(is.na(ORG_TP), "NONE", ORG_TP))

# CONVERT ALL CHARACTERS TO FACTOR
train_data2 <- train_data2 %>% mutate_if(is.character, as.factor)

# CHECK
str(train_data2)

# CONVERT RESPONSE VARIABLE TO FACTOR AND LABEL
x <- train_data2 %>% 
  select(SuperPAC_yes, party, first_file_date, last_file_date, CMTE_DSGN, CMTE_FILING_FREQ, CMTE_ST, TTL_CONTB, TTL_RECEIPTS, TTL_DISB, ORG_TP) %>% 
  mutate(SuperPAC_yes = as.factor(SuperPAC_yes),
         SuperPAC_yes = recode(SuperPAC_yes, `0` = "no", `1` = "yes"))

# CREATE RECIPE
rcp <- 
  recipe(SuperPAC_yes ~  .,x) %>% 
  step_knnimpute(TTL_CONTB, TTL_RECEIPTS, TTL_DISB, neighbors = 5) %>% 
  step_dummy(all_nominal(),-all_outcomes()) %>% 
  step_range(all_numeric()) %>%  # Normalize scale
  prep()

train_data_processed <- bake(rcp,x)
test_data_processed <- bake(rcp,x)

skimr::skim(train_data_processed)
skimr::skim(train_data_processed)

```

### Cross-Validation

```{r, include = FALSE}
## -------------------------------- Cross-Validation --------------------------------##

# set a seed for replication purposes 
set.seed(1988)

# Partition the data into 5 equal folds
folds <- createFolds(train_data_processed$SuperPAC_yes, k = 5) 

sapply(folds,length)

#Validation conditions
control_conditions <- 
  trainControl(method='cv', # K-fold cross validation
               summaryFunction = twoClassSummary, # classification problem
               classProbs = TRUE, # classification problem
               index = folds # The indices for our folds (so they are always the same)
  )

skimr::skim(train_data_processed)


```

# Results


- Give a detailed summary of your results.
– Present your results clearly and concisely.
– Please use visualizations and tables whenever possible.

## Models

```{r, echo = FALSE}
## ------------------------------------- Models -------------------------------------##


#Logit Model
mod_logit <-
  train(SuperPAC_yes ~ ., # Equation
        data=train_data_processed, # Training data 
        method = "glm", # logit function
        metric = "ROC", # area under the curve
        trControl = control_conditions
  )

mod_logit



#K-Nearest Neighbors Model

mod_knn <-
  train(SuperPAC_yes ~  ., # Equation (outcome and everything else)
        data=train_data_processed, # Training data 
        method = "knn", # K-Nearest Neighbors Algorithm
        metric = "ROC", # area under the curve
        trControl = control_conditions
  )

plot(mod_knn)

#K-Nearest Neighbors Model 2

knn_tune = expand.grid(k = c(1,3,10,50,60,70,80,100))
knn_tune

mod_knn2 <-
  train(SuperPAC_yes ~  ., # Equation (outcome and everything else)
        data=train_data_processed, # Training data 
        method = "knn", # K-Nearest Neighbors Algorithm
        metric = "ROC", # area under the curve
        tuneGrid = knn_tune,
        trControl = control_conditions
  )

plot(mod_knn2)


#CART

mod_cart <-
  train(SuperPAC_yes ~  ., # Equation (outcome and everything else)
        data=train_data_processed, # Training data 
        method = "rpart", # Classification Tree
        metric = "ROC", # area under the curve
        trControl = control_conditions
  )

plot(mod_cart)

#CART2

tune_cart2 <- expand.grid(cp = c(0.0001)) # Complexity Parameter (how "deep" our trees should grow)

mod_cart2 <-
  train(SuperPAC_yes ~ ., # Equation (outcome and everything else)
        data=train_data_processed, # Training data 
        method = "rpart", # Classification Tree
        metric = "ROC", # area under the curve
        tuneGrid = tune_cart2, # Tuning parameters
        trControl = control_conditions
  )


#Random Forest

mod_rf <-
  train(SuperPAC_yes ~ ., # Equation (outcome and everything else)
        data=train_data_processed, # Training data 
        method = "ranger", # random forest (ranger is much faster than rf)
        metric = "ROC", # area under the curve
        trControl = control_conditions
  )

plot(mod_rf)

fancyRpartPlot(mod_cart$finalModel)

```

## Model Comparison

```{r, echo = FALSE}
## ------------------------------------- Model Comparison  -------------------------------------##

mod_list <-
  list(
    knn1 = mod_knn,
    knn2 = mod_knn2,
    cart1 = mod_cart,
    cart2 = mod_cart2,
    rf = mod_rf,
    logit = mod_logit
  )

# Generate Plot to compare output. 
dotplot(resamples(mod_list))

```

## Predictive Performance

```{r, include = FALSE}
## ------------------------------------- Unpacking the Outcome: Predictive Performance -------------------------------------##

pred <- predict(mod_rf,newdata = test_data_processed)

confusionMatrix(table(pred,test_data_processed$SuperPAC_yes))

confusionMatrix(pred,test_data_processed$SuperPAC_yes,positive='yes')
```

## Variable Importance

```{r}
## ------------------------------------- Unpacking the Outcome: Variable Importance -------------------------------------##

# install.packages("vip") # Install the package
#pred_wrapper <- function(object, new_data) {
  # wrapper function so vip knows how to calculate a prediction
  #predict(object, data=new_data,type="response")$predictions[,"yes"]
#}

# Generate a variable importance plot
#permute_imp_plot <- 
 # vip::vip(mod_rf$finalModel,
          # data = train_data_processed,
          # target=train_data_processed$SuperPAC_yes,
          # train = train_data_processed %>% select(-SuperPAC_yes),
          # reference_class = "yes",
          # method="permute",
          # pred_wrapper = pred_wrapper)
```

## Partial Dependency

```{r}
## ------------------------------------- Unpacking the Outcome: Partial Dependency -------------------------------------##

# install.packages('pdp') Download the partial dependency plot
pdp_dat = pdp::partial(mod_rf, 
                        pred.var = c("first_file_date"), 
                        ice = F, 
                        center = F, 
                        prob = T,
                        type= "classification",
                        train = train_data_processed) 
pdp_dat

pdp_dat %>% 
  ggplot(aes(first_file_date,yhat)) + geom_line() +
  labs(y="Pr(SuperPAC_yes == 1)")
```

# Discussion

- Speak on the “success” of your project (as defined in your proposal).
  - Did you achieve what you set out to do? If not why?
– What tools/methods did you consider but not use in the final analysis?
– How would you expand the analysis if given more time?














